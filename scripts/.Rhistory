marker_list_R <- marker_list_R[ abs(marker_list_R$cor.r) > filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.r) > filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
#filter pearson p-value
if(!is.na(filter_thresholds[2]) | !(filter_thresholds[2])==0 ){
cat('\n Filtering interactions by Pearson p-value: ',filter_thresholds[2]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.pvalue) < filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.pvalue) < filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.pvalue) < filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all))}
#filter uniqueness
if(!is.na(filter_thresholds[3]) | !(filter_thresholds[3])==0 ){
cat('\n Filtering interactions by Pearson p-value: ',filter_thresholds[3]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$uniqueness) < filter_thresholds[3] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$uniqueness) < filter_thresholds[3] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$uniqueness) < filter_thresholds[3] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
marker_list_all
marker_list_L <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_L.csv',row.names = 1,stringsAsFactors = F)
marker_list_R <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_R.csv',row.names = 1,stringsAsFactors = F)
opt$filter_thresholds <- '0.1,0.1,3'
##############################################################
### FILTER INTERACTIONS BASED ON CORRELATION OR UNIQUENESS ###
##############################################################
filter_thresholds <- as.numeric(unlist(strsplit(opt$filter_thresholds,",")))
filter_thresholds
#filter pearson R
if(!is.na(filter_thresholds[1]) | !(filter_thresholds[1])==0 ){
cat('\n Filtering interactions by Pearson R: ',filter_thresholds[1]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.r) > filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.r) > filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.r) > filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
marker_list_L <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_L.csv',row.names = 1,stringsAsFactors = F)
marker_list_R <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_R.csv',row.names = 1,stringsAsFactors = F)
marker_list_all <- rbind(marker_list_L,marker_list_R)
#filter pearson R
if(!is.na(filter_thresholds[1]) | !(filter_thresholds[1])==0 ){
cat('\n Filtering interactions by Pearson R: ',filter_thresholds[1]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.r) > filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.r) > filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.r) > filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
#filter pearson p-value
if(!is.na(filter_thresholds[2]) | !(filter_thresholds[2])==0 ){
cat('\n Filtering interactions by Pearson p-value: ',filter_thresholds[2]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.pvalue) < filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.pvalue) < filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.pvalue) < filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all))}
#filter uniqueness
if(!is.na(filter_thresholds[3]) | !(filter_thresholds[3])==0 ){
cat('\n Filtering interactions by Pearson p-value: ',filter_thresholds[3]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$uniqueness) < filter_thresholds[3] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$uniqueness) < filter_thresholds[3] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$uniqueness) < filter_thresholds[3] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
marker_list_L <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_L.csv',row.names = 1,stringsAsFactors = F)
marker_list_R <- read.csv2('~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/analysis/5_Lig_Rec_interaction/Full_marker_list_R.csv',row.names = 1,stringsAsFactors = F)
marker_list_all <- rbind(marker_list_L,marker_list_R)
#filter pearson R
if(!is.na(filter_thresholds[1]) | !(filter_thresholds[1])==0 ){
cat('\n Filtering interactions by Pearson R: ',filter_thresholds[1]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.r) > filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.r) > filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.r) > filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
#filter pearson p-value
if(!is.na(filter_thresholds[2]) | !(filter_thresholds[2])==0 ){
cat('\n Filtering interactions by Pearson p-value: ',filter_thresholds[2]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$cor.pvalue) < filter_thresholds[1] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$cor.pvalue) < filter_thresholds[1] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$cor.pvalue) < filter_thresholds[1] ,]
cat('\n after filtering: ', nrow(marker_list_all))}
#filter uniqueness
if(!is.na(filter_thresholds[3]) | !(filter_thresholds[3])==0 ){
cat('\n Filtering interactions by uniqueness below or equal to: ',filter_thresholds[3]," ...")
cat('\n before filtering: ', nrow(marker_list_all))
marker_list_L <- marker_list_L[ abs(marker_list_L$uniqueness) <= filter_thresholds[3] ,]
marker_list_R <- marker_list_R[ abs(marker_list_R$uniqueness) <= filter_thresholds[3] ,]
marker_list_all <- marker_list_all[ abs(marker_list_all$uniqueness) <= filter_thresholds[3] ,]
cat('\n after filtering: ', nrow(marker_list_all)) }
k <- data.frame(t(as.data.frame(strsplit( c(marker_list_L$edge, marker_list_R$edge),split = ">"))))
all_genes <- unique(c(L_R_pairs$ligand,L_R_pairs$receptor))
datasets <- as.character(unique(unlist(k)[! (unlist(k) %in% all_genes)]))
colnames(k) <- c('ligand','receptor')
#k <- k[c(cors_FIB$signif_exp, cors_EPI$signif_cell),]
#k <- data.frame(L=c(L_R_pairs$ligand,k[,1]) , R=c(L_R_pairs$receptor,k[,2]),stringsAsFactors = F)
det_L_R_pairs <- L_R_pairs[ (L_R_pairs$ligand %in% as.character(k[,2])) & (L_R_pairs$receptor %in% as.character(k[,1])) , ]
k <- rbind(det_L_R_pairs , k)
rownames(det_L_R_pairs) <- 1:nrow(det_L_R_pairs)
det_L_R_pairs$uniqueness <- sapply( det_L_R_pairs$ligand, function(x) sum(det_L_R_pairs$ligand == x) )
marker_list_uniqueness <- data.frame(source=c(marker_list_L$cluster_name,marker_list_R$gene, det_L_R_pairs$ligand) ,
target=c(marker_list_L$gene,marker_list_R$cluster_name, det_L_R_pairs$receptor),
uniqueness=c(marker_list_L$uniqueness,marker_list_R$uniqueness,det_L_R_pairs$uniqueness) )
marker_list_uniqueness$edge <- paste0(marker_list_uniqueness$source,">",marker_list_uniqueness$target)
#Plot the Graph network of interacting Ligand-Receptors for fibroblasts and Epithelial cells
all_edges <- unlist(strsplit(paste(k$ligand,k$receptor,collapse = " ")," "))
g <- graph( edges=all_edges, directed=T )
g <- simplify(g, remove.multiple = T, remove.loops = T)
cols <- ifelse( V(g)$name %in% L_R_pairs$ligand,hue_pal()(10)[8],
ifelse( V(g)$name %in% L_R_pairs$receptor,hue_pal()(10)[4], hue_pal()(10)[1]) )
plot.igraph(g, vertex.label.color="black",vertex.label.family="sans",vertex.label.cex=.5,vertex.label.font=2,
vertex.shape="circle", vertex.size=10,edge.arrow.width=1,edge.arrow.size=.5,
vertex.color=paste0(cols,90 ),
vertex.frame.color=cols )
#Plot the Graph network of interacting Ligand-Receptors for fibroblasts and Epithelial cells
k <- k[ (k$ligand %in% k$receptor) | (k$receptor %in% k$ligand) , ]
all_edges <- unlist(strsplit(paste(k$ligand,k$receptor,collapse = " ")," "))
g <- graph( edges=all_edges, directed=T )
g <- simplify(g, remove.multiple = T, remove.loops = T)
cols <- ifelse( V(g)$name %in% L_R_pairs$ligand,hue_pal()(10)[8],
ifelse( V(g)$name %in% L_R_pairs$receptor,hue_pal()(10)[4], hue_pal()(10)[1]) )
l <- layout_with_sugiyama(g)
l <- l$layout[,2:1]
for (i in unique(l[,1])){  r <- rank( l[l[,1] == i ,2 ] ) ; l[l[,1] == i ,2 ] <- r / ( max(r)+1 ) }
print(length(unique(unlist(k))))
edge_info <- marker_list_uniqueness[match(paste(as_edgelist(g)[,1],as_edgelist(g)[,2],sep = ">"), marker_list_uniqueness$edge),"uniqueness"]
edge_color <- ifelse(is.na(edge_info),"black",ifelse(edge_info == 1,"black",ifelse(edge_info == 2,"grey50","grey70")))
edge_scalar <- ifelse(is.na(edge_info),.1,1/edge_info)
plot.igraph(g, vertex.label.color="black",vertex.label.family="sans",vertex.label.cex=1,vertex.label.font=2,
vertex.shape="vrectangle", vertex.size=25,vertex.size2=4/max(.6, length(unique(unlist(k)))/100 ),edge.arrow.width=edge_scalar*4,edge.arrow.size=0,
vertex.color=paste0(cols,90 ), vertex.frame.color=cols ,layout=-l,
edge.color=edge_color,edge.width=edge_scalar,asp = max(.6, length(unique(unlist(k)))/100 )  )
cat("printing metadata correlations")
cor_pal <- colorRampPalette(c("blue","navy","grey80","firebrick3","red"))(19)
myedges <- apply(as_edgelist(g),1,function(x) paste(x,collapse = ">"))
edge_cors <- marker_list_all[match(myedges,marker_list_all$edge),"cor.r"]
edge_info <- marker_list_uniqueness[match(paste(as_edgelist(g)[,1],as_edgelist(g)[,2],sep = ">"), marker_list_uniqueness$edge),"uniqueness"]
mycolor <- ifelse( is.na(edge_cors) , ifelse(edge_info == 1,"black",ifelse(edge_info == 2,"grey50","grey70")) , cor_pal[round( (edge_cors+1)*9+1,0)] )
edge_scalar <- ifelse(is.na(edge_info),.1,1/edge_info)
plot.igraph(g, vertex.label.color="black",vertex.label.family="sans",vertex.label.cex=1,vertex.label.font=2,
vertex.shape="vrectangle", vertex.size=25,vertex.size2=4/max(.6, length(unique(unlist(k)))/100 ),edge.arrow.width=edge_scalar*4,edge.arrow.size=0,
vertex.color=paste0(cols,90 ), vertex.frame.color=cols ,layout=-l,
edge.color=mycolor,edge.width=edge_scalar,asp = max(.6, length(unique(unlist(k)))/100 )  )
legend(-1,1.2,legend = c("clusters","ligands","receptors"),pch=22,xjust = 0,yjust = 1,
pt.bg = paste0(hue_pal()(10)[c(1,8,4)],90),bty = "n", col=hue_pal()(10)[c(1,8,4)] )
legend(-.5,1.2,legend = c("specific* (1 connection)","medium* (2 connections)","broad* (>2 connections)"),lty=1, xjust = 0,yjust = 1,lwd=c(2,2,1),
col = c("black","grey50","grey70"),bty = "n")
datasets
dtsts <- grep(paste0("^",sub("_.*","",i)), datasets,value = T)
opposite_dtsts <- datasets[!(datasets%in%dtsts)]
temp <- all_simple_paths(g, from = i, to = opposite_dtsts)
temp <- lapply(temp,function(x) x$name)
temp <- as.data.frame(t(as.data.frame(temp[unlist(lapply(temp,length)) == 4])))
temp_L_R_pairs <- L_R_pairs[ (L_R_pairs$ligand %in% temp[,2]) & (L_R_pairs$receptor %in% temp[,3]) , ]
k_temp <- rbind(temp_L_R_pairs,setNames(temp[,1:2],c("ligand","receptor")),setNames(temp[,3:4],c("ligand","receptor")), make.row.names = F)
k_temp <- k_temp[!duplicated(k_temp),]
all_edges_temp <- unlist(strsplit(paste(k_temp$ligand,k_temp$receptor,collapse = " ")," "))
g_temp <- graph( edges=all_edges_temp, directed=T )
g_temp <- simplify(g_temp, remove.multiple = T, remove.loops = T)
cols <- ifelse( V(g_temp)$name %in% L_R_pairs$ligand,hue_pal()(10)[8],
ifelse( V(g_temp)$name %in% L_R_pairs$receptor,hue_pal()(10)[4], hue_pal()(10)[1]) )
l <- layout_with_sugiyama(g_temp)
l <- l$layout[,2:1]
l
temp <- all_simple_paths(g, from = i, to = j)
temp
length(temp)
opposite_dtsts
i <- "R_all_cells_1"
dtsts <- grep(paste0("^",sub("_.*","",i)), datasets,value = T)
opposite_dtsts <- datasets[!(datasets%in%dtsts)]
dtsts
opposite_dtsts
grepl("L",i)
if(grepl("L",i)){ temp <- all_simple_paths(g, from = i, to = opposite_dtsts)
}else{            temp <- all_simple_paths(g, from = opposite_dtsts, to = i)  }
temp
opposite_dtsts
temp <- lapply(temp,function(x) x$name)
temp <- as.data.frame(t(as.data.frame(temp[unlist(lapply(temp,length)) == 4])))
temp_L_R_pairs <- L_R_pairs[ (L_R_pairs$ligand %in% temp[,2]) & (L_R_pairs$receptor %in% temp[,3]) , ]
k_temp <- rbind(temp_L_R_pairs,setNames(temp[,1:2],c("ligand","receptor")),setNames(temp[,3:4],c("ligand","receptor")), make.row.names = F)
k_temp <- k_temp[!duplicated(k_temp),]
k_temp
all_simple_paths(g, from = opposite_dtsts[2], to = i)
all_simple_paths(g, from = i, to = opposite_dtsts)
temp <- sapply( opposite_dtsts, function(x) all_simple_paths(g, from = x, to = i) )
temp
temp <- unlist(sapply( opposite_dtsts, function(x) all_simple_paths(g, from = x, to = i) ))
temp
temp <- lapply(sapply( opposite_dtsts, function(x) all_simple_paths(g, from = x, to = i) ),c)
temp
temp <- do.call(c,sapply( opposite_dtsts, function(x) all_simple_paths(g, from = x, to = i) ))
temp
temp
length(temp)
opt$input_path
opt$input_path <- '~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/data'
opt$dataset_metadata_path <- "~/Desktop/Desktop_stuff/MyProject/single_cell_analysis/data/metadata.csv"
dataset_metadata <- as.data.frame(read.csv2(opt$dataset_metadata_path))
as.character(dataset_metadata[,1])
print(as.character(dataset_metadata[,1]))
datasets <- list.dirs(opt$input_path,recursive = F,full.names = F)
datasets <- datasets[datasets %in% as.character(dataset_metadata[,1])]
datasets
sort(datasets)
i <- "sample1"
a <- Read10X(paste0(opt$input_path,"/",i))
colnames(a) <- paste0(colnames(a),"_",as.character(i))
a
library(Matrix)
#read .csv or .txt files
list.files(paste0(opt$input_path,"/",i))
grepl(".mtx", list.files(paste0(opt$input_path,"/",i))
grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))
sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i))))
sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) > 0
opt$input_path <- "~/Desktop/Desktop_stuff/MyProject/embrionic/data"
i <- "GSE122026"
paste0(opt$input_path,"/",i)
list.files(paste0(opt$input_path,"/",i))
grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T)
paste0(opt$input_path,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) )
#read .csv files
a <- sparseMatrix(read.csv2(paste0(opt$input_path,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ))
Read10X
#read .csv files
a <- as(read.csv2(paste0(opt$input_path,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ), Class = "dgCMatrix")
paste0(opt$input_path,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) )
grep(".csv", list.files(paste0(opt$input_path,"/",i))
grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T)
list.files(paste0(opt$input_path,"/",i))
#read .csv files
a <- as(read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ), Class = "dgCMatrix")
#read .csv files
a <- as(read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 ), Class = "dgCMatrix")
#read .csv files
a <- as(as.matrix(read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 ), Class = "dgCMatrix"))
#read .csv files
a <- as(as.matrix(read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )), Class = "dgCMatrix")
a
#read .csv files
a <- as.matrix(read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 ))
dim(a)
#read .csv files
a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
dim(a)
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
dim(a)
colnames(a)
sub("[_.,].*","","baksjda-asfsa")
sub("[_.,-].*","","baksjda-asfsa")
sub("[_.,-].*","","baksjda_asfsa")
sub("[_.,-].*","","baksjda__asfsa")
sub("[_.,-].*","","baksjda.asfsa")
library(parallel)
detectCores()
opt$input_path
datasets
opt$input_path <- "~/Desktop/Desktop_stuff/MyProject/embryonic/data"
opt$dataset_metadata_path <- "~/Desktop/Desktop_stuff/MyProject/embryonic/data/metadata.csv"
dataset_metadata <- as.data.frame(read.csv2(opt$dataset_metadata_path))
print(as.character(dataset_metadata[,1]))
cl
cl <- makeCluster(detectCores()-1,type = "FORK")
cl
dataset_metadata <- as.data.frame(read.csv2(opt$dataset_metadata_path))
print(as.character(dataset_metadata[,1]))
datasets <- list.dirs(opt$input_path,recursive = F,full.names = F)
datasets <- sort(datasets[datasets %in% as.character(dataset_metadata[,1])])
cat("\nThe following samples will be merged: ...\n")
print(datasets)
length(datasets) > 1
i <- datasets[1]
#for(i in sort(datasets) ){
cat("\nloading datasets\n")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, 1:length(datasets), opt=opt,function(i,opt){
print(i)
i <- datasets[i]
print(i)
print(opt)
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
1:length(datasets)
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, 1:length(datasets), opt=opt,function(i,opt){
print(i)
i <- datasets[i]
print(i)
print(opt)
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
cl
opt
1:length(datasets)
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, 1:length(datasets), function(i){
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
data
print(lapply(data,dim))
?parLapplyLB
data <- parLapplyLB(cl, datasets, function(i){
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
i
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, 1:length(datasets), function(x){
i <- datasets[x]
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
checkForRemoteErrors()
data <- parLapplyLB(cl, datasets, function(x){
i <- x
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, datasets, function(x){
require(Seurat)
require(Matrix)
require(utils)
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
cat("\nDimension of loaded datasets\n")
print(lapply(data,dim))
x
i
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, datasets, function(x){
print(x)
require(Seurat)
require(Matrix)
require(utils)
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
data
print(lapply(data,dim))
datasets
parLapplyLB(cl, datasets, function(x){print(x)})
cat("\nloading datasets\n")
cl <- makeCluster(detectCores()-1,type = "FORK")
clusterExport(cl, varlist = c("datasets","opt") )
data <- parLapplyLB(cl, datasets, function(i){
require(Seurat)
require(Matrix)
require(utils)
if( sum(grepl(".mtx", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read 10X files
a <- Seurat::Read10X(paste0(opt$input_path,"/",i))
} else if  ( sum(grepl(".csv", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.csv(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )
if(ncol(a) == 0){a <- read.csv2(paste0(opt$input_path,"/",i,"/",grep(".csv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = 1 )}
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
} else if  ( sum(grepl(".tsv|.txt", list.files(paste0(opt$input_path,"/",i)))) == 1 ){
#read .csv files
a <- read.delim(paste0(opt$input_path,"/",grepl(".txt|.tsv", list.files(paste0(opt$input_path,"/",i)),value = T) ),row.names = T ,header = T)
a <- Matrix::Matrix(as.matrix(rowsum(a,sub("[_.,].*","",rownames(a)))),sparse=T)
}
colnames(a) <- paste0(colnames(a),"_",as.character(i))
#assign(i, CreateSeuratObject(a,project=i,min.cells = 1,min.features = 1),envir = .GlobalEnv)
cat("The size of dataset", i, " is: ", dim(a),"\n" )
return(a)
})
cat("\nDimension of loaded datasets\n")
print(lapply(data,dim))
#}
cat("Merging datasets\n" )
#DATA <- merge(get(sort(datasets)[1]), y=mget(sort(datasets)[-1]),all=T)
clusterExport(cl, varlist = c("data") )
all_genes <- unique(unlist(parLapplyLB(cl,data,function(x) return(rownames(x)))))
all_genes
#DATA <- merge(get(sort(datasets)[1]), y=mget(sort(datasets)[-1]),all=T)
clusterExport(cl, varlist = c("") )
print(length(all_genes))
clusterExport(cl, varlist = c("all_genes") )
data <- parLapplyLB(cl, data, all_genes=all_genes,function(x,all_genes) {
m <- Matrix::Matrix(0,nrow = length(all_genes), ncol = ncol(x),sparse = T,dimnames = list(all_genes,colnames(x)))
m[rownames(x),] <- x
return(m)
})
data
print(lapply(data,dim))
DATA <- do.call(cbind,data)
rm(data); invisible(gc())
